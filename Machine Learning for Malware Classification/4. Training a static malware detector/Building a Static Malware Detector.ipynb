{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we build on the previous exercises to prepare a labeled dataset of binary feature vectors, and use it to train a *Random Forest* binary classifier of malware/benign feature vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/asci/.cache/pip/wheels/2c/19/61/c79689ef799ed5062f1376a5628fd8427cad5df1e7e15fd095/pefile-2019.4.18-py3-none-any.whl\n",
      "Processing /home/asci/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94/future-0.18.2-py3-none-any.whl\n",
      "Installing collected packages: future, pefile\n",
      "Successfully installed future-0.18.2 pefile-2019.4.18\n"
     ]
    }
   ],
   "source": [
    "# To install pefile, uncomment and execute the following line:\n",
    "!pip install pefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directoriesWithLabels = [(\"Samples/Benign\",0), (\"Samples/Malware\",1)]\n",
    "listOfSamples = []\n",
    "labels = []\n",
    "for datasetPath, label in directoriesWithLabels:\n",
    "    samples = [f for f in os.listdir(datasetPath)]\n",
    "    for file in samples:\n",
    "        filePath = os.path.join(datasetPath, file)\n",
    "        listOfSamples.append(filePath)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "samples_train, samples_test, labels_train, labels_test = train_test_split(listOfSamples, labels, test_size=0.33, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "import pefile\n",
    "\n",
    "def readFile(filePath):\n",
    "    with open(filePath, \"rb\") as binary_file:\n",
    "        data = binary_file.read()\n",
    "    return data\n",
    "\n",
    "def byteSequenceToNgrams(byteSequence, n):\n",
    "    Ngrams = ngrams(byteSequence, n)\n",
    "    return list(Ngrams)\n",
    "    \n",
    "def extractNgramCounts(file, N):\n",
    "    fileByteSequence = readFile(file)\n",
    "    fileNgrams = byteSequenceToNgrams(fileByteSequence, N)\n",
    "    return collections.Counter(fileNgrams)\n",
    "\n",
    "def getNGramFeaturesFromSample(file, K1_most_common_Ngrams_list):\n",
    "    K1 = len(K1_most_common_Ngrams_list)\n",
    "    fv = K1*[0]\n",
    "    fileNgrams = extractNgramCounts(file, N)\n",
    "    for i in range(K1):\n",
    "        fv[i]=fileNgrams[K1_most_common_Ngrams_list[i]]\n",
    "    return fv\n",
    "\n",
    "def preprocessImports(listOfDLLs):\n",
    "    processedListOfDLLs = []\n",
    "    temp = [x.decode().split(\".\")[0].lower() for x in listOfDLLs]\n",
    "    return \" \".join(temp)\n",
    "\n",
    "def getImports(pe):\n",
    "    listOfImports = []\n",
    "    for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
    "        listOfImports.append(entry.dll)\n",
    "    return preprocessImports(listOfImports)\n",
    "\n",
    "def getSectionNames(pe):\n",
    "    listOfSectionNames = []\n",
    "    for eachSection in pe.sections:\n",
    "        refined_name = eachSection.Name.decode().replace('\\x00','').lower()\n",
    "        listOfSectionNames.append(refined_name)\n",
    "    return \" \".join(listOfSectionNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2-Grams, \n",
    "# and produce feature vectors based on the frequency method\n",
    "# This may take a few minutes to run\n",
    "N=2\n",
    "totalNgramCount = collections.Counter([])\n",
    "for file in samples_train:\n",
    "    totalNgramCount += extractNgramCounts(file, N)\n",
    "K1 = 100\n",
    "K1_most_common_Ngrams = totalNgramCount.most_common(K1)\n",
    "K1_most_common_Ngrams_list = [x[0] for x in K1_most_common_Ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples/Benign/oisicon.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Samples/Benign/malias.exe:\n",
      "'Invalid e_lfanew value, probably not a PE file'\n",
      "Samples/Benign/Common.DBConnection64.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Samples/Benign/FixSqlRegistryKey_ia64.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Samples/Benign/fsynonym.exe:\n",
      "'Invalid e_lfanew value, probably not a PE file'\n",
      "Samples/Benign/newmail.exe:\n",
      "'Invalid e_lfanew value, probably not a PE file'\n",
      "Samples/Benign/evntwin.exe:\n",
      "'DOS Header magic not found.'\n",
      "Samples/Benign/LockAppHost.exe:\n",
      "'DOS Header magic not found.'\n",
      "Samples/Benign/adaminstall.exe:\n",
      "'DOS Header magic not found.'\n",
      "Samples/Benign/lc.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Samples/Malware/VirusShare_7a30183b105b4200fc201925aba4886c.exe:\n",
      "'utf-8' codec can't decode byte 0xb8 in position 0: invalid start byte\n",
      "Samples/Malware/VirusShare_14f3035781bb698c37ad287483af569e.exe:\n",
      "'utf-8' codec can't decode byte 0x8d in position 0: invalid start byte\n",
      "Samples/Benign/ldifde.exe:\n",
      "'DOS Header magic not found.'\n",
      "Samples/Benign/BootExpCfg.exe:\n",
      "'DOS Header magic not found.'\n",
      "Samples/Benign/SettingSyncHost.exe:\n",
      "'DOS Header magic not found.'\n",
      "Samples/Benign/aspnetca.exe:\n",
      "'DOS Header magic not found.'\n"
     ]
    }
   ],
   "source": [
    "# Extract N-gram features based on the frequency method\n",
    "# Also, extracts some metadata such as DLL imports, \n",
    "# and PE Sections. We will combine these with\n",
    "# our N-gram features to enrich the sample representation.\n",
    "# This will take a few minutes to run.\n",
    "# Some samples will generate errors such as 'not a PE file',\n",
    "# 'DOS header not found', and 'invalid attribute'. These are OK.\n",
    "importsCorpus_train = []\n",
    "numSections_train = []\n",
    "sectionNames_train = []\n",
    "NgramFeaturesList_train = []\n",
    "y_train = []\n",
    "for i in range(len(samples_train)):\n",
    "    file = samples_train[i]\n",
    "    try:\n",
    "        NGramFeatures = getNGramFeaturesFromSample(file, K1_most_common_Ngrams_list)\n",
    "        pe = pefile.PE(file)\n",
    "        imports = getImports(pe)\n",
    "        nSections = len(pe.sections)\n",
    "        secNames = getSectionNames(pe)\n",
    "        importsCorpus_train.append(imports)\n",
    "        numSections_train.append(nSections)\n",
    "        sectionNames_train.append(secNames)\n",
    "        NgramFeaturesList_train.append(NGramFeatures)\n",
    "        y_train.append(labels_train[i])\n",
    "    except Exception as e: \n",
    "        print(file+\":\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following lines, we define a pipeline of sequential transforms (HashingVectorizer and TfidfTransformer) to extract N-gram featurs and construct feature vectors from the DLL imports and Section names extracted for each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "imports_featurizer = Pipeline([('vect', HashingVectorizer(input='content', ngram_range=(1, 2))),('tfidf', TfidfTransformer(use_idf=True, )),])\n",
    "section_names_featurizer = Pipeline([('vect', HashingVectorizer(input='content', ngram_range=(1, 2))),('tfidf', TfidfTransformer(use_idf=True, )),])\n",
    "importsCorpus_train_transformed = imports_featurizer.fit_transform(importsCorpus_train)\n",
    "sectionNames_train_transformed = section_names_featurizer.fit_transform(sectionNames_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the binary N-gram features with \n",
    "# the DLL imports and section names features to create\n",
    "# vectorized training samples\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "X_train = hstack([NgramFeaturesList_train, importsCorpus_train_transformed,sectionNames_train_transformed, csr_matrix(numSections_train).transpose()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the Random Forest classifier\n",
    "# This may take a few minutes.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=1)\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9978991596638656"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training accuracy\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples/Malware/VirusShare_1a89b7d4fb8ded72e1f8e81ee9352262.exe:\n",
      "'utf-8' codec can't decode byte 0xb1 in position 0: invalid start byte\n",
      "Samples/Benign/RegAsm.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Samples/Benign/urlproxy.exe:\n",
      "'Invalid NT Headers signature. Probably a NE file'\n",
      "Samples/Benign/sysprep.exe:\n",
      "'DOS Header magic not found.'\n",
      "Samples/Benign/pmsort.exe:\n",
      "'Invalid e_lfanew value, probably not a PE file'\n",
      "Samples/Benign/InstallUtil.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Samples/Benign/FixSqlRegistryKey_x64.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Samples/Benign/pmgrant.exe:\n",
      "'Invalid e_lfanew value, probably not a PE file'\n",
      "Samples/Benign/LogCollector.exe:\n",
      "'DOS Header magic not found.'\n"
     ]
    }
   ],
   "source": [
    "# Generate feature vectors for the test samples\n",
    "# This may take a few minutes\n",
    "importsCorpus_test = []\n",
    "numSections_test = []\n",
    "sectionNames_test = []\n",
    "NgramFeaturesList_test = []\n",
    "y_test = []\n",
    "for i in range(len(samples_test)):\n",
    "    file = samples_test[i]\n",
    "    try:\n",
    "        NGramFeatures = getNGramFeaturesFromSample(file, K1_most_common_Ngrams_list)\n",
    "        pe = pefile.PE(file)\n",
    "        imports = getImports(pe)\n",
    "        nSections = len(pe.sections)\n",
    "        secNames = getSectionNames(pe)\n",
    "        importsCorpus_test.append(imports)\n",
    "        numSections_test.append(nSections)\n",
    "        sectionNames_test.append(secNames)\n",
    "        NgramFeaturesList_test.append(NGramFeatures)\n",
    "        y_test.append(labels_test[i])\n",
    "    except Exception as e: \n",
    "        print(file+\":\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "importsCorpus_test_transformed = imports_featurizer.transform(importsCorpus_test)\n",
    "sectionNames_test_transformed = section_names_featurizer.transform(sectionNames_test)\n",
    "X_test = hstack([NgramFeaturesList_test, importsCorpus_test_transformed,sectionNames_test_transformed, csr_matrix(numSections_test).transpose()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9786324786324786"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** The training and test accuracies are unusually high. Can you propose a diagnosis for these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results may be due to a variety of causes, including but not limited to: \n",
    "- poorly selected N-gram \n",
    "- a skewed dataset or skewed classes \n",
    "- overfitting of the data being evaluated \n",
    "\n",
    "In order to identify if one of the above is the issue, further evaluation of the dataset and train/test pattern is required. \n",
    "To do this, first the N-gram can be changed to different values to see which is the best fit for this dataset. \n",
    "Identifying if the dataset has a higher level of one value or identifier over the other is another important action to see if the dataset is skewed and would be improper to continue working with in it's current condition. \n",
    "Finally, testing with new data can help identify if the data is overfit, and if so further evaluation of the model being used must be done to avoid this. \n"
    "It is also possible that a different model is best for this type of data, to identify this further testing would be required. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
